{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUDIT-C Final Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:49.028617Z",
     "start_time": "2018-12-28T19:56:19.029775Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import matplotlib.pyplot as plt\n",
    "import synapseclient\n",
    "from synapseclient import Activity, Schema, Table, as_table_columns\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from tqdm import tqdm\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "syn = synapseclient.Synapse()\n",
    "syn.login()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:50.539364Z",
     "start_time": "2018-12-28T19:56:49.034767Z"
    }
   },
   "outputs": [],
   "source": [
    "v1sid, v2sid =  'syn10250481', 'syn9974011'\n",
    "\n",
    "v1r = pd.read_excel(syn.get(v1sid).path, parse_dates=['response_utc'])\n",
    "v2r = pd.read_csv(syn.get(v2sid).path, parse_dates=['createdAt'])\n",
    "\n",
    "v1r.head()\n",
    "v2r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process V1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:50.631879Z",
     "start_time": "2018-12-28T19:56:50.549284Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the uneeded columns\n",
    "v1 = v1r.drop(columns=[\n",
    "    'sent_time_local', 'sent_time_utc', 'response_local', 'response_id', 'user_id', 'audit'\n",
    "]).rename(columns={\n",
    "    'brightenid': 'participant_id',\n",
    "    'audit1':'alc_1',\n",
    "    'audit2':'alc_2',\n",
    "    'audit3':'alc_3',\n",
    "    'response_utc':'dt_response'\n",
    "})\n",
    "\n",
    "# add qsum\n",
    "v1['alc_sum'] = [t.alc_1 + t.alc_2 + t.alc_3 for t in v1.itertuples()]\n",
    "\n",
    "v1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process V2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:50.677513Z",
     "start_time": "2018-12-28T19:56:50.638478Z"
    }
   },
   "outputs": [],
   "source": [
    "v2 = v2r.drop(columns=['day'])\\\n",
    "     .rename(columns={\n",
    "        'How often did you have a drink containing alcohol in the past year?':'alc_1',\n",
    "        'How many drinks did you have on a typical day when you were drinking in the past year?':'alc_2',\n",
    "        'How often did you have six or more drinks on one occasion in the past year?':'alc_3',\n",
    "        'username':'participant_id',\n",
    "        'createdAt': 'dt_response'\n",
    "})\n",
    "\n",
    "# add qsum\n",
    "v2['alc_sum'] = [t.alc_1 + t.alc_2 + t.alc_3 for t in v2.itertuples()]\n",
    "\n",
    "v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-01T19:26:25.708447Z",
     "start_time": "2018-11-01T19:26:25.674402Z"
    }
   },
   "source": [
    "### Combine the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:50.729409Z",
     "start_time": "2018-12-28T19:56:50.681538Z"
    }
   },
   "outputs": [],
   "source": [
    "combined = pd.concat([v1, v2], sort=False)\n",
    "\n",
    "# order the columns\n",
    "combined = combined.loc[:,\n",
    "    ['participant_id', 'dt_response', 'alc_1', 'alc_2', 'alc_3', 'alc_sum']\n",
    "]\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:51.179216Z",
     "start_time": "2018-12-28T19:56:50.734231Z"
    }
   },
   "outputs": [],
   "source": [
    "combined.alc_1.hist()\n",
    "combined.alc_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:51.550085Z",
     "start_time": "2018-12-28T19:56:51.182225Z"
    }
   },
   "outputs": [],
   "source": [
    "combined.alc_2.hist()\n",
    "combined.alc_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:52.018046Z",
     "start_time": "2018-12-28T19:56:51.556009Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "combined.alc_3.hist()\n",
    "combined.alc_3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add week into study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:53.373952Z",
     "start_time": "2018-12-28T19:56:52.022856Z"
    }
   },
   "outputs": [],
   "source": [
    "metasid = 'syn17023349'\n",
    "metadata = syn.tableQuery(f'SELECT participant_id, startdate FROM {metasid}').asDataFrame(convert_to_datetime=True)\n",
    "metadata.startdate = pd.to_datetime(metadata.startdate)\n",
    "\n",
    "# add in the participants start date as a new column\n",
    "combined = pd.merge(combined, metadata, on='participant_id', how='left')\n",
    "\n",
    "# get the time difference in weeks as a float\n",
    "combined['week'] = [\n",
    "    d.days/7 for d in (\n",
    "        combined.dt_response.apply(\n",
    "            lambda x: dt.datetime(year=x.year, month=x.month, day=x.day))-combined.startdate\n",
    "    )\n",
    "]\n",
    "\n",
    "# convert the week number to an int by taking the floor\n",
    "combined.week = combined.week.progress_apply(lambda x: np.int16(np.floor(x))+1)# if not pd.isnull(x) else np.nan)\n",
    "\n",
    "# remove the start date\n",
    "combined = combined.drop(columns=['startdate'], errors='ignore')\n",
    "\n",
    "# reorder the columns\n",
    "cols = list(combined.columns)\n",
    "cols = cols[0:2] + ['week'] + cols[2:-1]\n",
    "combined = combined.reindex(columns=cols)\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localize timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:56:53.441743Z",
     "start_time": "2018-12-28T19:56:53.380441Z"
    }
   },
   "outputs": [],
   "source": [
    "# localize timestamps\n",
    "combined['dt_response'] = [\n",
    "    str(t.tz_localize('UTC'))\n",
    "    for t in combined.dt_response\n",
    "]\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set provenance and upload to Synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:57:06.768298Z",
     "start_time": "2018-12-28T19:56:53.445815Z"
    }
   },
   "outputs": [],
   "source": [
    "t = syn.delete(\n",
    "    syn.tableQuery('select * from syn17021280')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:57:18.583050Z",
     "start_time": "2018-12-28T19:57:06.771592Z"
    }
   },
   "outputs": [],
   "source": [
    "final = syn.store(Table(\n",
    "    Schema(\n",
    "            name='AUDIT-C',\n",
    "            columns=as_table_columns(combined), \n",
    "            parent='syn10848316'),\n",
    "        combined\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:57:19.398110Z",
     "start_time": "2018-12-28T19:57:18.596069Z"
    }
   },
   "outputs": [],
   "source": [
    "final = syn.setProvenance(\n",
    "    'syn17021280',\n",
    "    activity=Activity(\n",
    "        name='Combine V1 and V2 data',\n",
    "        description='Process and combine the data collected during study 1 and study 2',\n",
    "        used=[v1sid, v2sid],\n",
    "        executed=[\n",
    "            dict(\n",
    "                name='IPython Notebook',\n",
    "                url='https://github.com/apratap/BRIGHTEN-Data-Release/blob/master/Create_Alcohol_datafiles.ipynb'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bright]",
   "language": "python",
   "name": "conda-env-bright-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
