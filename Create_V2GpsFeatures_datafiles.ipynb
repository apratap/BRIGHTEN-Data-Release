{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T16:55:00.426251Z",
     "start_time": "2018-12-28T16:54:51.968679Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datetime as dt\n",
    "import itertools as it\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import synapseclient\n",
    "from synapseclient import Activity, Schema, Table, as_table_columns\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "syn = synapseclient.Synapse()\n",
    "syn.login()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T16:55:01.062175Z",
     "start_time": "2018-12-28T16:55:00.527720Z"
    }
   },
   "outputs": [],
   "source": [
    "v2sid = 'syn17037408'\n",
    "v2r = pd.read_csv(syn.get(v2sid).path, parse_dates=['date']).rename(columns={\n",
    "    'username':'participant_id',\n",
    "    'date':'dt_passive'\n",
    "})\n",
    "\n",
    "leading = ['participant_id', 'dt_passive']\n",
    "v2 = v2r.reindex(labels=\n",
    "    leading + sorted(list(set(v2r.columns)-set(leading))),\n",
    "    axis=1                  \n",
    ")\n",
    "\n",
    "v2.location_variance = np.round(v2.location_variance, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the week in to the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T16:55:12.953187Z",
     "start_time": "2018-12-28T16:55:06.880718Z"
    }
   },
   "outputs": [],
   "source": [
    "metasid = 'syn17023349'\n",
    "metadata = syn.tableQuery(f'SELECT participant_id, startdate FROM {metasid}').asDataFrame(convert_to_datetime=True)\n",
    "metadata.startdate = pd.to_datetime(metadata.startdate)\n",
    "\n",
    "# add in the participants start date as a new column\n",
    "v2 = pd.merge(v2, metadata, on='participant_id', how='left')\n",
    "\n",
    "# exclude any rows before the start date\n",
    "v2 = v2.loc[(v2.dt_passive >= v2.startdate) | v2.dt_passive.isnull()]\n",
    "\n",
    "# get the time difference in weeks as a float\n",
    "v2['week'] = [\n",
    "    d.days/7 for d in (\n",
    "        v2.dt_passive.apply(\n",
    "            lambda x: dt.datetime(year=x.year, month=x.month, day=x.day))-v2.startdate\n",
    "    )\n",
    "]\n",
    "\n",
    "# convert the week number to an int by taking the floor\n",
    "v2.week = v2.week.progress_apply(lambda x: np.int16(np.floor(x)) if not pd.isnull(x) else np.nan)\n",
    "\n",
    "# remove the start date\n",
    "v2 = v2.drop(columns=['startdate'], errors='ignore')\n",
    "\n",
    "# reorder the columns\n",
    "cols = list(v2.columns)\n",
    "cols = cols[0:2] + ['week'] + cols[2:-1]\n",
    "v2 = v2.reindex(columns=cols)\n",
    "\n",
    "v2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-26T21:54:40.794503Z",
     "start_time": "2018-12-26T21:54:40.591417Z"
    }
   },
   "source": [
    "### Reduce dt_passive to date only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T16:57:35.689915Z",
     "start_time": "2018-12-28T16:57:35.551299Z"
    }
   },
   "outputs": [],
   "source": [
    "v2.dt_passive = v2.dt_passive.apply(lambda x: x.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to Synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T16:58:12.146415Z",
     "start_time": "2018-12-28T16:57:43.956405Z"
    }
   },
   "outputs": [],
   "source": [
    "t = syn.delete(\n",
    "    syn.tableQuery('select * from syn17061218')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T16:58:30.261416Z",
     "start_time": "2018-12-28T16:58:12.153851Z"
    }
   },
   "outputs": [],
   "source": [
    "final = syn.store(Table(\n",
    "    Schema(\n",
    "            name='GPS Features (v2)',\n",
    "            columns=as_table_columns(v2), \n",
    "            parent='syn10848316'),\n",
    "        v2\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T16:58:30.862913Z",
     "start_time": "2018-12-28T16:58:30.270144Z"
    }
   },
   "outputs": [],
   "source": [
    "final = syn.setProvenance(\n",
    "    'syn17061218',\n",
    "    activity=Activity(\n",
    "        name='Generate Public GPS (v2) Table Data',\n",
    "        description='Process the data collected during study ',\n",
    "        used=[v2sid],\n",
    "        executed=[\n",
    "            dict(\n",
    "                name='IPython Notebook',\n",
    "                url='https://github.com/apratap/BRIGHTEN-Data-Release/blob/master/Create_V2GpsFeatures_datafiles.ipynb'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T16:58:30.928970Z",
     "start_time": "2018-12-28T16:58:30.867865Z"
    }
   },
   "outputs": [],
   "source": [
    "cheat = []\n",
    "headers = ['#', 'Variable Name', 'Data Type', 'Description']\n",
    "\n",
    "for c in v2.columns:\n",
    "    cheat.append((c, str(v2[c].dtype)\\\n",
    "          .replace('object', 'str')\\\n",
    "          .replace('float64', 'float')\\\n",
    "          .replace('int16', 'int')\\\n",
    "          .replace('int64', 'int')\\\n",
    "          .replace('datetime64[ns]', 'DateTime')\n",
    "     ))\n",
    "    \n",
    "descriptions = [\n",
    "    'Unique ID',                    # participant id\n",
    "    'Date of aggregated data',      # dt_passive\n",
    "    '$$\\(\\in \\)$$ { _true_, _false_ } indicating whether or not the participant came to work',\n",
    "    'The cumulative distance traveled in the _active_ velocity bin (_meters_)', # distance_activate\n",
    "    'The cumulative distance traveled in the _high speed transportation_ velocity bin (_meters_)',\n",
    "    'The cumulative distance traveled in the _powered vehicle_ velocity bin (_meters_)',\n",
    "    'The cumulative distance traveled in the _walking_ velocity bin (_meters_)',\n",
    "    'The count of hours in the day for which GPS records exist ',\n",
    "    'The cumulative time spent in the _active_ velocity bin (_hours_)',\n",
    "    'The cumulative time spent in the _home_ cluster (_hours_)',\n",
    "    'The cumulative time spent in the _work_ cluster  (_hours_)',\n",
    "    'The cumultive time spent in the _high speed transportation_ velocity bin (_hours_)',\n",
    "    'The estimated hours of sleep accrued during the previous night (_hours_)',\n",
    "    'The cumulative time spent in the _powered vehicle_ velocity bin (_hours_)',\n",
    "    'The cumulative time spent in the participants top 3 most visited clusters throughout the study period (_hours_)',\n",
    "    'The cumulative time spent in the _stationary_ velocity bin (_hours_)',\n",
    "    'The cumulative time spent in the _stationary_ velocity bin excluding the time spent in the home and work clusters (_hours_)',\n",
    "    'The cumulative time spent in the _walking_ velocity bin (_hours_)',\n",
    "    'The count of hours in the day for which GPS does not exist',\n",
    "    'log($$\\(\\sigma^2_{\\text{lat}}+\\sigma^2_{\\text{lon}}\\)$$)',\n",
    "    'The distinct number of clusters visited'\n",
    "]\n",
    "\n",
    "cheat = pd.DataFrame(\n",
    "    cheat, \n",
    "    columns=headers[1:-1],\n",
    "    index=np.arange(1, len(cheat)+1)\n",
    ")\n",
    "\n",
    "cheat['Description'] = descriptions + ['' for i in range(len(descriptions), len(cheat))]\n",
    "\n",
    "print(tabulate(\n",
    "    cheat,\n",
    "    headers=headers,\n",
    "    tablefmt='orgtbl'\n",
    ").replace('+', '|'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bright]",
   "language": "python",
   "name": "conda-env-bright-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
