{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHQ2 Final Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:30.214763Z",
     "start_time": "2018-12-28T19:58:09.059128Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import synapseclient\n",
    "from synapseclient import Activity, Schema, Table, as_table_columns\n",
    "from tqdm import tqdm\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "syn = synapseclient.Synapse()\n",
    "syn.login()\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:37.634147Z",
     "start_time": "2018-12-28T19:58:30.224527Z"
    }
   },
   "outputs": [],
   "source": [
    "v1_raw_id, v2_raw_id = 'syn10250486', 'syn9974012'\n",
    "\n",
    "v1r = pd.read_excel(syn.get(v1_raw_id).path)\n",
    "v2r = pd.read_csv(syn.get(v2_raw_id).path, parse_dates=['createdAt'])\n",
    "\n",
    "v1r.head()\n",
    "v2r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process V1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:38.843056Z",
     "start_time": "2018-12-28T19:58:37.644692Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop the uneeded columns\n",
    "v1r = v1r.drop(columns=[\n",
    "    'sent_time_local', 'sent_time_utc', 'response_utc', 'response_id', 'user_id', 'start', 'phq2'\n",
    "]).rename(columns={\n",
    "    'brightenid': 'participant_id',\n",
    "    'Feeling down, depressed, or hopeless.': 'phq2_1',\n",
    "    'Little interest or pleasure in doing things.': 'phq2_2',\n",
    "})\n",
    "\n",
    "# add in yesterdays date\n",
    "def dx(x):\n",
    "    t = x-dt.timedelta(days=1)\n",
    "    return dt.date(year=t.year, month=t.month, day=t.day)\n",
    "\n",
    "v1r['dt_yesterday'] = v1r.response_local.apply(dx)\n",
    "\n",
    "# add qsum\n",
    "v1r['phq2_sum'] = [t.phq2_1 + t.phq2_2 for t in v1r.itertuples()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process V2 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:39.096490Z",
     "start_time": "2018-12-28T19:58:38.847694Z"
    }
   },
   "outputs": [],
   "source": [
    "# rename some columns\n",
    "v2r = v2r.rename(columns={\n",
    "    'YESTERDAY, were you bothered by any of the following problems? Feeling down, depressed, or hopeless.':'phq2_1',\n",
    "    'YESTERDAY, were you bothered by any of the following problems? Irritable or Anxious?':'phq2_2',\n",
    "    'username':'participant_id',\n",
    "    'createdAt': 'response_local'\n",
    "})\n",
    "\n",
    "# add yesterdays date\n",
    "v2r['dt_yesterday'] = v2r.response_local.apply(dx)\n",
    "\n",
    "# add qsum\n",
    "v2r['phq2_sum'] = [t.phq2_1 + t.phq2_2 for t in v2r.itertuples()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:39.190450Z",
     "start_time": "2018-12-28T19:58:39.103680Z"
    }
   },
   "outputs": [],
   "source": [
    "combined = pd.concat([v1r, v2r], sort=False)\n",
    "combined = combined.loc[:,\n",
    "    ['participant_id', 'response_local', 'dt_yesterday', 'day', 'phq2_1', 'phq2_2', 'phq2_sum']\n",
    "].rename(columns={'response_local':'dt_response'})\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:39.601033Z",
     "start_time": "2018-12-28T19:58:39.196218Z"
    }
   },
   "outputs": [],
   "source": [
    "combined.phq2_1.hist(bins=5, rwidth=.8)\n",
    "combined.phq2_1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:40.030845Z",
     "start_time": "2018-12-28T19:58:39.605655Z"
    }
   },
   "outputs": [],
   "source": [
    "combined.phq2_2.hist(bins=5, rwidth=.8)\n",
    "combined.phq2_2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add week into study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:43.200755Z",
     "start_time": "2018-12-28T19:58:40.036535Z"
    }
   },
   "outputs": [],
   "source": [
    "metasid = 'syn17023349'\n",
    "metadata = syn.tableQuery(f'SELECT participant_id, startdate FROM {metasid}').asDataFrame(convert_to_datetime=True)\n",
    "metadata.startdate = pd.to_datetime(metadata.startdate)\n",
    "\n",
    "# add in the participants start date as a new column\n",
    "combined = pd.merge(combined, metadata, on='participant_id', how='left')\n",
    "\n",
    "# get the time difference in weeks as a float\n",
    "combined['week'] = [\n",
    "    d.days/7 for d in (\n",
    "        combined.dt_response.apply(\n",
    "            lambda x: dt.datetime(year=x.year, month=x.month, day=x.day))-combined.startdate\n",
    "    )\n",
    "]\n",
    "\n",
    "# convert the week number to an int by taking the floor\n",
    "combined.week = combined.week.progress_apply(lambda x: np.int16(np.floor(x))+1)# if not pd.isnull(x) else np.nan)\n",
    "\n",
    "# remove the start date\n",
    "combined = combined.drop(columns=['startdate'], errors='ignore')\n",
    "\n",
    "# reorder the columns\n",
    "cols = list(combined.columns)\n",
    "cols = cols[0:2] + ['week'] + cols[2:-1]\n",
    "combined = combined.reindex(columns=cols)\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Localize timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:58:44.822951Z",
     "start_time": "2018-12-28T19:58:43.204064Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# localize timestamps\n",
    "combined['dt_response'] = [\n",
    "    str(t.tz_localize('UTC'))\n",
    "    for t in combined.dt_response\n",
    "]\n",
    "\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set provevance and upload to Synapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:59:24.453755Z",
     "start_time": "2018-12-28T19:58:44.828099Z"
    }
   },
   "outputs": [],
   "source": [
    "t = syn.delete(\n",
    "    syn.tableQuery('select * from syn17020855')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:59:47.980289Z",
     "start_time": "2018-12-28T19:59:24.458653Z"
    }
   },
   "outputs": [],
   "source": [
    "phq2_final = syn.store(Table(\n",
    "    Schema(\n",
    "            name='PHQ-2',\n",
    "            columns=as_table_columns(combined), \n",
    "            parent='syn10848316'),\n",
    "        combined\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-28T19:59:49.120237Z",
     "start_time": "2018-12-28T19:59:47.983803Z"
    }
   },
   "outputs": [],
   "source": [
    "phq2_final = syn.setProvenance(\n",
    "    'syn17020855',\n",
    "    activity=Activity(\n",
    "        name='Combine V1 and V2 data',\n",
    "        description='Process and combine the data collected during study 1 and study 2',\n",
    "        used=[v1_raw_id, v2_raw_id, metasid],\n",
    "        executed=[\n",
    "            dict(\n",
    "                name='IPython Notebook',\n",
    "                url='https://github.com/apratap/BRIGHTEN-Data-Release/blob/master/Create_PHQ2_datafiles.ipynb'\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bright]",
   "language": "python",
   "name": "conda-env-bright-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
