---
title: "2 Preparing and Staging Data"
output:
  html_document:
    df_print: paged
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE, 
                      message = FALSE,
                      cache = FALSE)


```

# Summary

Only certain files from our original data are desired. These will be moved to a staging area for further work.

Files names will be unified across the repository in order to make their presentation consistent for clients. 

# Environment

Python and the Synapse python library will need to be setup in the environment. Other variables and R libraries are fully configured here. Enter your username and password for Synapse.org.

```{r Setting Environment}
#Needed Libraries 
# Setup loop to check in library is installed....
#library(synapser) #Synapse API
#library(knitr) #command line option in compiling notebook
#library(tools)
#library(xlsx) #read xmls files
#library(data.table) 
#library(reticulate) #Python integration into R studio
#library(stringr) #parse strings
source("./CustomFunctions.R")

#library(PythonInR) #required to use some of sysapse API

#some libraries are used from python
synapseclient <- import('synapseclient')
synapseutils <- import('synapseutils')

#Constants
#File locations and directories
DATADIRECTORY <- "./Data/"
STAGINGAREA <- paste(DATADIRECTORY, "New/", sep = "")
REPORTDIRECTORY <- "./Reports/2_"

dir.create(STAGINGAREA)

SYNLOGIN <- synapseclient$login() #generate synology login token
```

# Load Local Functions

These are convienence functions for processees in this notebook. Functions common to working with synapse and our datda in general can be found in ../CustomFunctons.R

```{r}
#remove data type
#sent_time_local
#sent_time_utc
clean.user.names <- function(DF) {
  `%!in%` <- Negate('%in%')
  tested<- names(DF)
  for(i in 1:length(tested)) {
    from <- c("user_id", 
              "response_id",
              "Response ID",
              "Username",
              "userId")

  
    
    if (tested[[i]] %in% from) tested[[i]] <- tolower(gsub("[^A-Za-z]","",tested[[i]]))
  }
  names(DF) <- tested
  if ("responseid" %in% names(DF)) {
    DF <- subset(DF, select = -responseid) 
  }
  if ("username" %in% names(DF)) {
    DF$userid <- DF$username
    DF <- subset(DF, select = -username)
  }
  if ("sent_time_local" %in% names(DF)) {
    DF <- subset(DF, select = -sent_time_local)
  }
  if ("sent_time_utc" %in% names(DF)) {
    DF <- subset(DF, select = -sent_time_utc)
  }
  if ("createdAt" %in% names(DF)) {
    DF$timestamp <- DF$createdAt
    DF$createdAt <- NULL
  }
  if ("response_local" %in% names(DF)) {
    DF$timestamp <- DF$"response_local"
    DF$"response_local" <- NULL
  }
  if ("response_utc" %in% names(DF)) {
    DF$"timestampUTC" <- DF$"response_utc"
    DF$"response_utc" <- NULL
  }
  if ("week" %in% names(DF)) {
    DF <- subset(DF, select = -week)
  }
  if ("day" %in% names(DF)) {
    DF <- subset(DF, select = -day)
  }
  if ("start" %in% names(DF)) {
    if("timestamp" %!in% names(DF)) {
      DF$date <- DF$start
    }
    DF$start <- NULL
  }
  return(DF)
}
```

# Loading File Information

Records Generated in Chapter 1 are used to identify and organize files in this step.

```{r load_file_descriptions}
MatchedRecords <- read.csv("./Reports/1_LocalMatchedRecords.csv", stringsAsFactors = FALSE)

FileInformation <- read.csv("./Reports/1_LocalFileInformation.csv", stringsAsFactors = FALSE)

```

# Extract Transform and Stage Indicated Files

Files indicated in [the online files description document](https://docs.google.com/spreadsheets/d/1_EDCpmYlkZZNuRb4D1ueq-HU5Klqkpih_cmzCDSh24w/edit#gid=1705651418) are modified and staged for upload in step 3.

## Study Metadata
brighten_v1_study_metadata.tsv
final_mdata_20180105172418-surveyexport_edited_apratap.txt

```{r load_Study_Metadata}
#Extract
V1 <- find.data(MatchedRecords[4,]$V1Path)
V2 <- find.data(MatchedRecords[28,]$V2Path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)
V2 <- clean.user.names(V2)

#Removing Identifiable Information
V1 <- subset(V1, select = -c(Age,State))
V2 <- subset(V2, select = -c(ip_address, longitude, latitude, city, state))

V2$timestamp <- V2$time_submitted
#removing unnecessary data
V1 <- subset(V1, select = -c(baseline_phq9, study_arm))
V2 <- subset(V2, select = -c(userAgent, time_started, time_submitted, onBoardingTime, sum_phq9, sum_phq10, Referer, heard_about_us, heard_about_us_language))  

#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_MetaData.csv", sep = ""), row.names = FALSE)
write.csv(V2 , paste(DATADIRECTORY, "New/V2_MetaData.csv", sep = ""), row.names = FALSE)


```

## Passive Features

brighten_v1_passive_features.tsv
passivedata_brighten_v2.tsv

```{r load_passive_features_data}
#exract
V1 <- find.data(MatchedRecords[1,]$V1Path)
V2 <- find.data(MatchedRecords[1,]$V2Path)


#Transform
#fix usernames
V1 <- clean.user.names(V1)
V2 <- clean.user.names(V2)

#removing unneeded time variables
V1$passive_date_pacific <- NULL
V2$date <- V2$passive_date
V2$passive_date <- NULL

V1$study_arm <- NULL

#These two data frames appear to be substantially different. 
#It is not clear how call duration in the V1 file might be transformed to the hours provided in the V2 file.
#It is not clear how the sms length from V1 might be reconciled to the text length received, and text length sent vairables from V2
#The same is true for call duration
#It is not clear if/how missed interactions in V1 might be build from Call duration missed from V2

#V1 delete day week start

#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_Passive_Features.csv", sep = ""), row.names = FALSE)
write.csv(V2 , paste(DATADIRECTORY, "New/V2_Passive_Features.csv", sep = ""), row.names = FALSE)

```

## PHQ-2

brighten_v1_phq2_scores.tsv
phq2_brighten_v2.tsv

```{r load_PHQ2_data}
#Extract
V1 <- find.data(MatchedRecords[2,]$V1Path)
V2 <- find.data(MatchedRecords[2,]$V2Path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)
V2 <- clean.user.names(V2)

#removing unused time data
V1 <- subset(V1, select = -c(study_arm, phq2ResponseTimeSecs, phq2_date_local))

V2$timestamp <- V2$phq2_timestamp
V2 <- subset(V2, select = -c(phq2_timestamp, phq2_date, phq2_date_minus_one, phq2_hod))


#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_PHQ2.csv", sep = ""), row.names = FALSE)
write.csv(V2 , paste(DATADIRECTORY, "New/V2_PHQ2.csv", sep = ""), row.names = FALSE)
```

## PHQ-9
brighten_v1_phq9_scores.tsv
phq9_brighten_v2.tsv

```{r load_PHQ9_data}
#Extract
V1 <- find.data(MatchedRecords[3,]$V1Path)
V2 <- find.data(MatchedRecords[3,]$V2Path)
V1b <- find.data(MatchedRecords[24,]$V1Path)

#Transform
#attaching V1 phq9 questions
V1$phq9_1 <- V1b$ph1
V1$phq9_2 <- V1b$ph2
V1$phq9_3 <- V1b$ph3
V1$phq9_4 <- V1b$ph4
V1$phq9_5 <- V1b$ph5
V1$phq9_6 <- V1b$ph6
V1$phq9_7 <- V1b$ph7
V1$phq9_8 <- V1b$ph8
V1$phq9_9 <- V1b$ph9
V1b$transfer <- V1b$phdis
levels(V1b$transfer) <- c(3,0,1,2)
V1$phq9_10 <- V1b$transfer

#fix usernames
V1 <- clean.user.names(V1)
V2 <- clean.user.names(V2)

#removing timing
V1 <- subset(V1, select = -c(phq9ResponseTimeSecs, sum_phq10, sum_phq9))
V2 <- subset(V2, select = -c(phq9_date, phq9_hod, sum_phq9))
V2$timestamp <- V2$phq9_timestamp
V2$phq9_timestamp <- NULL

#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_PHQ9.csv", sep = ""), row.names = FALSE)
write.csv(V2 , paste(DATADIRECTORY, "New/V2_PHQ9.csv", sep = ""), row.names = FALSE)
```

## Energy Levels

energylevels_404.xls

```{r load_mental_health_screening}

#Extract
V1 <- find.data(MatchedRecords[5,]$V1Path)
#V2 <- find.data(MatchedRecords[5,]$V2Path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)

names(V1)[3] <- "screen_1"
names(V1)[4] <- "screen_2"
names(V1)[5] <- "screen_3"
names(V1)[6] <- "screen_4"


#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_mhealthscreen.csv", sep = ""), row.names = FALSE)
#write.csv(V2 , paste(DATADIRECTORY, "New/V2_EnergyLevels.csv", sep = ""), row.names = FALSE)

```

## GAD-7
gad7_402.xls

```{r load_GAD-7}
#Extract
V1 <- find.data(MatchedRecords[6,]$V1Path)
#V2 <- find.data(MatchedRecords[6,]$V2Path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)
V1$gad7 <- NULL
#change variables to gad_
names(V1) <- c("brightenid","userid","gad7_1","gad7_2","gad7_3","gad7_4","gad7_5","gad7_6","gad7_7","gad7_S", 'timestamp', 'timestampUTC')
levels(V1$gad7_S) <- c(3,0,1,2)


write.csv(V1 , paste(DATADIRECTORY, "New/V1_GAD7.csv", sep = ""), row.names = FALSE)
#write.csv(V2 , paste(DATADIRECTORY, "New/V2_GAD7.csv", sep = ""), row.names = FALSE)

```

## Health Apps
healthapps_405.xls

```{r load_Health_apps}

#Extract
V1 <- find.data(MatchedRecords[7,]$V1Path)
#V2 <- find.data(MatchedRecords[7,]$V2Path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)
#renaming variables
names(V1)[3] <- "happ_1"
names(V1)[4] <- "happ_2"


#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_HealthApps.csv", sep = ""), row.names = FALSE)
#write.csv(V2 , paste(DATADIRECTORY, "New/V2_HealthApps.csv", sep = ""), row.names = FALSE)

```

## Mental Health Services
mentalhealthservices_400.xls
impact-mh.csv

```{r load_Mental_Health_Services}
#Extract
V1 <- find.data(MatchedRecords[8,]$V1Path)
V2 <- find.data(MatchedRecords[8,]$V2Path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)
V2 <- clean.user.names(V2)
names(V1)[3] <- "mhs_1"
names(V1)[4] <- "mhs_2"
names(V1)[5] <- "mhs_3"
names(V1)[6] <- "mhs_4"
names(V1)[7] <- "mhs_5"
names(V2)[1] <- "mhs_1"
names(V2)[2] <- "mhs_2"
names(V2)[3] <- "mhs_3"
names(V2)[4] <- "mhs_4"
names(V2)[5] <- "mhs_5"

#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_MentalHealthSvc.csv", sep = ""), row.names = FALSE)
write.csv(V2 , paste(DATADIRECTORY, "New/V2_MentalHealthSvc.csv", sep = ""), row.names = FALSE)

```


## Mood Assessment
moodassessment_407.xls

```{r load_mood_assessment}
#Extract
V1 <- find.data(MatchedRecords[9,]$V1Path)
#V2 <- find.data(MatchedRecords[9,]$V2Path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)

#rename question and levels
names(V1)[3] <- "mood_1"

#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_MoodAssessment.csv", sep = ""), row.names = FALSE)
#write.csv(V2 , paste(DATADIRECTORY, "New/V2_MoodAssessment.csv", sep = ""), row.names = FALSE)

```


## Sleep
sleep_406.xls
sleep_brighten_v2.tsv
sleep.csv

```{r load_sleep}
#Extract
V1 <- find.data(MatchedRecords[10,]$V1Path)
#V2 <- find.data(MatchedRecords[10,]$V2Path)
V2 <- find.data(FileInformation[FileInformation$fileName == "sleep.csv",]$path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)
V2 <- clean.user.names(V2)

#renamin variables
names(V1)[3] <- "sleep_1"
names(V1)[4] <- "sleep_2"
names(V1)[5] <- "sleep_3"
names(V2)[1] <- "sleep_1"
names(V2)[2] <- "sleep_2"
names(V2)[3] <- "sleep_3"
levels(V1$sleep_1) <- c(1,2,3,4,5)
levels(V1$sleep_2) <- c(2,3,4,1,5)
levels(V1$sleep_3) <- c(1,2,3,4,5)

#sleep.csv contains the full questionsand an extra variable "day" which I assume to be day in study, but is otherwise the same as sleep_brighten_v2.tsv. It is not clear what solution is desired here, but both were requested in the "files to keep"

#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_Sleep.csv", sep = ""), row.names = FALSE)
write.csv(V2 , paste(DATADIRECTORY, "New/V2_sleep.csv", sep = ""), row.names = FALSE)

```


## Alchohol Use
alcoholuse_403.xls

```{r load_alchohol_use}

#Extract
V1 <- find.data(FileInformation[FileInformation$fileName == "alcoholuse_403.xls",]$path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)

#It is not clear what is being measures here or if any change is necessary

#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_AlchoholUse.csv", sep = ""), row.names = FALSE)


```


## Apps
apps_399.xls

```{r load_apps}

#Extract
V1 <- find.data(FileInformation[FileInformation$fileName == "apps_399.xls",]$path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)
#rename answer
names(V1)[3] <- "otherapps_1"


#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_Apps.csv", sep = ""), row.names = FALSE)


```

## Apps Satisfaction
ppsatisfaction_408.xls

```{r load_apps_satisfaction}
#Extract
V1 <- find.data(FileInformation[FileInformation$fileName == "appsatisfaction_408.xls",]$path)

#Transform
#fix usernames
V1 <- clean.user.names(V1)

#renaming questions
names(V1)[3] <- "satis_1"
names(V1)[4] <- "satis_2"
names(V1)[5] <- "satis_3"
names(V1)[6] <- "satis_4"
#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_AppsSatisfaction.csv", sep = ""), row.names = FALSE)


```

## SDS
qualityoflife_401.xls
sds_brighten_v2.tsv

```{r load_Sheehan_Disability_Scale}
#Extract
V1 <- find.data(FileInformation[FileInformation$fileName == "qualityoflife_401.xls",]$path)
V2 <- find.data(FileInformation[FileInformation$fileName == "sds_brighten_v2.tsv",]$path)

  #Transform
#fix usernames
V1 <- clean.user.names(V1)
V2 <- clean.user.names(V2)
#Aligning Variable Names from V1 to match V2
names(V1)[3] <- "sds_1"
names(V1)[4] <- "sds_2"
names(V1)[5] <- "sds_3"
names(V2)[1] <- "stress"
names(V2)[2] <- "support"
V1$sds <- NULL
V2$sds_hod <- NULL
V2$sds_score <- NULL
V2$sds_date <- NULL

V2$timestamp <- V2$sds_timestamp
V2$sds_timestamp <- NULL

#Load
write.csv(V1 , paste(DATADIRECTORY, "New/V1_SDS.csv", sep = ""), row.names = FALSE)
write.csv(V2 , paste(DATADIRECTORY, "New/V2_SDS.csv", sep = ""), row.names = FALSE)


```

## GPS Agg
gps_agg_brighten_v2.tsv

```{r load_GPS_Agg_DISABLED, eval=FALSE, include=FALSE}
#Extract
V2 <- find.data(FileInformation[FileInformation$fileName == "gps_agg_brighten_v2.tsv",]$path)

#Transform
#fix usernames
V2 <- clean.user.names(V2)
#Removing identifying information
V2 <- subset(V2, select = -c(longitude, latitude))
#*** note with this removed, there is little of value in this file, only a collection of users who have GPS information.

#Load
#write.csv(V2 , paste(DATADIRECTORY, "New/V2_GPSAgg.csv", sep = ""), row.names = FALSE)


```

## GPS Features
gps_features_brighten_v2.tsv

```{r load_GPS_Features}
#Extract
V2 <- find.data(FileInformation[FileInformation$fileName == "gps_features_brighten_v2.tsv",]$path)

#Transform
#fix usernames
V2 <- clean.user.names(V2)
#Remove identifying information
V2 <- subset(V2, select = -c(med_lon_perDay,med_lat_perDay))
#standardizing unique date name
V2$date <- V2$gps_date
V2$gps_date <- NULL

#Load
write.csv(V2 , paste(DATADIRECTORY, "New/V2_GPSFeatures.csv", sep = ""), row.names = FALSE)
```
